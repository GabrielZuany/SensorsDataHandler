{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IndustriALL AI Challenge\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Reading Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFOLDER = '../data/'\n",
    "BASE_NAME = 'TAG_iALL_PS_'\n",
    "full_csv_exists = 'full.csv' in os.listdir(DATAFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_csv_exists:\n",
    "    start_time = time.time()\n",
    "    full_df = pd.read_csv('../data/full.csv')\n",
    "    end_time = time.time()\n",
    "    print('Elapsed time: ' + str(end_time - start_time) + ' seconds')\n",
    "\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    def read(file):\n",
    "        if file.endswith('00.csv'):\n",
    "            return None\n",
    "\n",
    "        print('Reading file: ' + file)\n",
    "        df = pd.read_csv(DATAFOLDER + file)\n",
    "        df = df.set_index('timestamp')\n",
    "\n",
    "        return df[file.split('.')[0]]\n",
    "\n",
    "    files_to_process = [file for file in os.listdir(DATAFOLDER) if not file.endswith('00.csv')]\n",
    "\n",
    "    # Use ProcessPoolExecutor for parallel processing\n",
    "    with ProcessPoolExecutor(cpu_count()) as executor:\n",
    "        # Map the function to process each file in parallel\n",
    "        dfs = list(executor.map(read, files_to_process))\n",
    "\n",
    "    # Create the full_df by concatenating the DataFrames\n",
    "    full_df = pd.concat([pd.read_csv(DATAFOLDER + 'TAG_iALL_PS_00.csv').set_index('timestamp')] + dfs, ignore_index=False, axis=1)\n",
    "\n",
    "    # Rename the 'target_iALL_PS' column to 'status' \n",
    "    if 'target_iALL_PS.csv' in files_to_process:\n",
    "        full_df = full_df.rename(columns={'target_iALL_PS': 'status'})\n",
    "\n",
    "    # Save the result to a CSV file\n",
    "    full_df.to_csv(DATAFOLDER + 'full.csv')\n",
    "    end_time = time.time()\n",
    "    print('Elapsed time: ' + str(end_time - start_time) + ' seconds')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Filtering and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for col in full_df.columns:\n",
    "    print(f\"{col} : {full_df[col].dtype}\", end=\" | \")\n",
    "    count += 1\n",
    "    if count % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and NaNs (when all rows/columns are NaN)\n",
    "full_df = full_df.drop_duplicates()\n",
    "full_df = full_df.dropna(axis=1, how='all')\n",
    "full_df = full_df.dropna(axis=0, how='all')\n",
    "full_df = full_df.reset_index()\n",
    "\n",
    "# Convert the timestamp column to datetime and set it as the index\n",
    "full_df['timestamp'] = pd.to_datetime(full_df['timestamp'])\n",
    "full_df = full_df.sort_values(by='timestamp')\n",
    "full_df = full_df.reset_index()\n",
    "full_df = full_df.set_index('timestamp') if 'timestamp' in full_df.columns else full_df\n",
    "\n",
    "# Create a column with the status as a boolean (might be useful for plotting later)\n",
    "full_df['status_bool'] = np.where(full_df['status'] == 'NORMAL', 0, 1)\n",
    "\n",
    "# drop the columns that are not useful\n",
    "full_df = full_df.drop(columns=['index'])\n",
    "full_df = full_df.drop(columns=['level_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to find and return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_in_series(series:pd.Series):\n",
    "    \"\"\"Find outliers in a pandas Series using the interquartile range (IQR) method.\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): The Series to find outliers in.\n",
    "\n",
    "    Returns:\n",
    "        _type_: A Series with the outliers.\n",
    "    \"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Calculate the upper and lower bounds\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    df_cpy = series.copy()\n",
    "    \n",
    "    # set not outliers to NaN\n",
    "    df_cpy[(df_cpy >= lower_bound) & (df_cpy <= upper_bound)] = np.nan\n",
    "\n",
    "    return df_cpy\n",
    "\n",
    "def find_outliers(df:pd.Series | pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Find outliers in a pandas Series or DataFrame using the interquartile range (IQR) method.\n",
    "\n",
    "    Args:\n",
    "        df (pd.Series | pd.DataFrame): The Series or DataFrame to find outliers in.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with the outliers.\n",
    "    \"\"\"\n",
    "    all_columns = df.columns if isinstance(df, pd.DataFrame) else [df.name]\n",
    "    outliers = pd.DataFrame()\n",
    "    for column in all_columns:\n",
    "        if df[column].dtype == 'object' or column == 'status':\n",
    "            continue\n",
    "        outliers[column] = find_outliers_in_series(df[column])\n",
    "            \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_df['status'].value_counts())\n",
    "print(full_df['status'].value_counts(normalize=True))\n",
    "\n",
    "# drop rows with all NaN values\n",
    "outliers = find_outliers(full_df)\n",
    "outliers = outliers.dropna(how='all') \n",
    "print(f\"Outliers: {outliers.shape[0]}\")\n",
    "\n",
    "# build dataframes with only ANORMAL status\n",
    "non_normal_df = full_df[full_df['status'] == 'ANORMAL']\n",
    "print(f\"Non normal: {non_normal_df.shape[0]}\")\n",
    "\n",
    "# drop rows with all NaN values\n",
    "non_normal_and_outlier = find_outliers(non_normal_df)\n",
    "non_normal_and_outlier = non_normal_and_outlier.dropna(how='all') \n",
    "print(f\"Non normal and outlier: {non_normal_and_outlier.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pratical exemple of the code above using TAG 00 as example\n",
    "\n",
    "print(\"Full TAG 00 data:\")\n",
    "print(full_df['TAG_iALL_PS_00'].describe())\n",
    "\n",
    "print(\"\\nNon normal TAG 00 data:\")\n",
    "print(non_normal_df['TAG_iALL_PS_00'].describe())\n",
    "\n",
    "print(\"\\nOutliers in TAG 00:\")\n",
    "print(outliers['TAG_iALL_PS_00'].describe())\n",
    "\n",
    "print(\"\\nOutliers in non normal TAG 00:\")\n",
    "print(non_normal_and_outlier['TAG_iALL_PS_00'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# boxplot of TAG_iALL_PS_00 (example)\n",
    "fig = px.box(full_df, y='TAG_iALL_PS_00', color='status')\n",
    "fig.update_layout(title='TAG_iALL_PS_00 boxplot', yaxis_title='TAG_iALL_PS_00')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Check the correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df.corr(numeric_only=True)\n",
    "fig, ax = plt.subplots(figsize=(60,30))\n",
    "sns.heatmap(full_df.corr(numeric_only=True), annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_status_1 = full_df.corr('pearson', numeric_only=True)['status_bool'].sort_values(ascending=False)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(corr_status_1.to_frame(), annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes using Gaussian/Bernoulli Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes Theorem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "1) So, in our case:\n",
    "\n",
    "    - P(y|X) = (P(X|y) * P(y)) / P(X)\n",
    "    - y is the class labels tath we want to predict and X is the feature vector given by (X=x1, x2, x3, ...m xn)\n",
    "\n",
    "    Then, we assume that features are mutually independent\n",
    "    So, addume that, we can split it into different componenets:\n",
    "    - P(y|X) = (P(x1|y) * P(x2|y) * ... * P(xn|y) * P(y)) / P(X)\n",
    "\n",
    "<br>\n",
    "\n",
    "2) Select the class with highest posterior probability\n",
    "\n",
    "    - y = argmax(y)P(y|X) = argmax(y)(P(x1|y) * P(x2|y) * ... * P(xn|y) * P(y)) / P(X)\n",
    "    - to simplify the formula, we can throw away the P(X) because this not depends os y at all:\n",
    "        - y = argmax(y)P(y|X) = argmax(y)(P(x1|y) * P(x2|y) * ... * P(xn|y) * P(y))\n",
    "\n",
    "    - all the probabilities are values between 0 and 1, so we can tranform it in a sum o log(k) values:\n",
    "        - y = argmax(y)P(y|X) = argmax(y)(log(P(x1|y)) + log(P(x2|y)) + ... + log(P(xn|y)) + log(P(y)))\n",
    "\n",
    "<br>\n",
    "\n",
    "3) Prior and class conditional\n",
    "\n",
    "    - P(y) is the Prior probability ---> frequency of each class\n",
    "    - P(xi|y) is the class conditional probability ---> Model with Gaussian\n",
    "\n",
    "    - ![image.png](attachment:image.png)\n",
    "\n",
    "4) Main Steps\n",
    "    - Training:\n",
    "        - Calculate mean, var and prior (frequency) of each class\n",
    "    - Predictions:\n",
    "        - Calculate posterior for each class with: \n",
    "        > y = argmax(y)P(y|X) = argmax(y)(log(P(x1|y)) + log(P(x2|y)) + ... + log(P(xn|y)) + log(P(y)))\n",
    "    - Choose the highest posterior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# set nan values to 0. The missing values might not affect the model\n",
    "full_df = full_df.fillna(0)\n",
    "\n",
    "# create a list of features\n",
    "features = full_df.columns.tolist()\n",
    "features.remove('status')\n",
    "features.remove('status_bool')\n",
    "\n",
    "# create a list of target\n",
    "target = 'status'\n",
    "\n",
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(full_df[features], full_df[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# create a Gaussian and Bernoulli Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "# predict the response for test dataset\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "y_pred_bnb = bnb.predict(X_test)\n",
    "\n",
    "# print the first 10 anormal predictions\n",
    "def print_result_sample(y_pred, y_test):\n",
    "    first_10_anormal_predictions = []\n",
    "    first_10_anormal_actual = []\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == 'ANORMAL':\n",
    "            first_10_anormal_predictions.append(y_pred[i])\n",
    "            first_10_anormal_actual.append(y_test[i])\n",
    "            if len(first_10_anormal_predictions) == 10:\n",
    "                break\n",
    "\n",
    "    print(first_10_anormal_predictions)\n",
    "    print(first_10_anormal_actual)\n",
    "\n",
    "print(f\"\\nGNB accuracy: {accuracy_score(y_test, y_pred_gnb)}\")\n",
    "print_result_sample(y_pred_gnb, y_test)\n",
    "print(f\"\\nBNB accuracy: {accuracy_score(y_test, y_pred_bnb)}\")\n",
    "print_result_sample(y_pred_bnb, y_test)\n",
    "\n",
    "# check how many predictions match between the two models\n",
    "print(f\"\\nNumber of matching predictions: {np.sum(y_pred_gnb == y_pred_bnb)} / {len(y_pred_gnb)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
